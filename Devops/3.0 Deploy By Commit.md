# Steps to DevOps - Deploy by Commit


One goal of DevOps, CICD, and Automation is to have your product “Deploy By Commit” - What does this mean? Ultimately it means that all changes to your product in Prod Environments are only done through an automation pipeline with the only human interaction one or two approval steps. This pipeline should be triggered when a commit is made to your Main branch. If you are thinking critically about this, you will realize this means that any commit made to your branch should start of a deployment. This is true! This is the ultimate goal of CICD - No branches, no multiple longstanding environments like Dev and Stage and what not - just Prod, and an extensive testing and automation pipeline that deploys to production.

There are many pieces that line up to this, and any sensible developer is going to look at their team, their product, their test suites and logically come to the conclusion that such a thing is a pipe dream. Never going to happen, no way could we do that.

And you know what? Most likely the dev is completely correct given the current state of things with their team and product

However, remember. We’re developers. Every problem we face may seem insurmountable at first. But we pick away at it. We make small steps forward until we have solved it. We do this naturally with code and with technical problems because we have experience with the parts we will need to solve the problem. We can also apply this same way of thinking to CICD and DevOps!


## Alright. What is at minimum needed to say I am Deploying by Commit?


If you want to confidently say your team is deploying by commit, then you need to be able to check off several things (Don’t worry! We’ll go more into detail about them soon) In order of Importance, but somewhat reverse order of execution:


### Immutable Production Environment


*Production Environments will:*

* deny the ability of anyone to edit them manually in a programic manner.
 * e.g. IaM, Service Principles, Permissions to use the Portal denied
* only be able to be changed by Infrastructure as Code sources.
 * e.g. Terraform, CDK, ect
* only allow IaC resource to touch the Production Environment through the pipeline.
* No local initiated deployments that skip the pipeline
* directly be tied to a specific Commit Sha in the originating Repo that is a complete snapshot of the code required to create/re-create that deployment environment at any time.


### [Reliable Testing of the Environment and App](2.0%20Reliable%20Testing.md)
 

*In order for testing to be reliable, it must:*
 
* be automated so as to remove human potential for mistakes and variance.
* be made against ephemeral test environments that are stood up and destroyed as part of the testing.
* generate said ephemeral environments from the Infrastructure as Code sources of the app and be completely workable so as to guarantee an identical testing environment.
* fail the pipeline and stop the deployment if any test fails.

 

### Provisioning of Environment and Resources 100% Automated

*In order for Provisioning to be 100% automated, it must:*

 
* be completely and entirely defined in an Infrastructure as Code framework.
 * e.g. Terraform, Terragrunt, CDK, ect
* contain Zero resource adjustments that are not replicated in the IaC files.
 * Scripts that contain the necessary commands are IaC in a way!
* be able to be destroyed just as effectively as deployed.
* be able to be deployed multiple times in the same ‘account’ (ie Subscription Group) without errors.

 

### The Pipeline is triggered by a commit to “Main” and Main is protected


*In order for Main to be protected it must:*
 

* be only updatable through Pull Request with Human Approval.
* trigger Test Automation on Pull Request Opened, that must past before a merge can be done.
* have standards and style automated and approved before a Pull Request is merged.
 * e.g. Linting, Test Coverage
* annotate the PR comments with the results of testing for history and record keeping.


**There are several other things that go into this that are outside the direct chain of this process. For example:**


### An App and its dependant infrastructure are contained only within one Repo


*A single repo is important because:*


* Deployment on your app should not rely on the deployment of another repo to happen first.
 * Tightly coupled deployments like this limit the ability of your team to deploy when you want
 * This is a Microservice principle, but it is still good to follow with CICD practices
 * If your app relies on other repos you do not control the tests within those in the same pipeline, making it impossible to say with reasonable certainty that the app is working as intended when the tests complete (Because several tests were not run and part of the coupled app has changed!)


> Note! A situation where you bundle an image, adn then pass that image off to another service (based out of another repo) to be deployed is OK!
> * The app inside an image will have been 100% tested, and the entire purpose of a container images is reliable and replicable environments.
> * The Infrastructure around said app will either have already been deployed OR will be contained as part of your IaC files the service that deploys your app will initiate on its own.
>  * As long as you have tested all of those factors in ephemeral, ad-hoc environments that are destroyed immediately after you can be certain they will act as designed when spun up again in the container service pipeline.
 

### Deployment should happen often and in small increments of change


*Small change, often made deployments are important because:*


* Large amounts of changes are harder to be reasonably certain that the changes are properly tested.
* There are simply too many permutations of changes interacting for it to be reasonable to assume all scenarios were covered!
* Large amounts of changes are often contained in long lived branches, which far to often will get out of sync with Main.


### Linting and Testing is automated on PRs being Opened


*These can be done a variety of ways, such as:*


* Anything you build or use that can interact with the Github Commit Status API such as:
 * Any pipeline service such as CodePipeline in AWS, AzureDevops, Github Actions
 * A container that is used as part of an automated process.
 * A serverless function that is triggered from a github webhook.
* Tools like Pre-Commit for doing so in a devs local or if you have an Enterprise Github server, Server Sided Pre-Commit hooks.
 * Pre-Commit is great, but requires all of your developers to have it installed and work with it.  This can be a requirement, but it's always nebulous because it is out of a pipelines automation control and therefore cannot be relied upon to exist.
 * Server-side hooks however are not always available!
* A combination of these plus automation triggered above is the best solution.

 

### A Trunk Based git strategy should be used, and there should be no long living branches

*Long lived branches (and possibly Environments) lead to issues because:*
 

* Long lived branches (such as Dev, Stage, Pre-Prod) encourage environments that match.
* There will be drift between Main (which represents production) and the long lived branch.
* Drift between environments means that what is being tested in a “lower environment” does not match what is actually happening in prod.
* Any tests run against an environment represented by a branch that is not Main has no way of being 100% accurate against Main, and therefor is useless.


### Test Driven Development (or some variant therein) should be used.


*TDD, BDD, or similar help:*


* give confidence and reliability that the tests are covering the actual behavior of the code
* help make code that is smaller, more unit based, and less coupled
 * which leans into the need to make commits and deployments that are smaller and more often

 

### Have team engage with and own Team Guidelines


* Code Style Guideline Docs
* Commit Message and Pull Request guidelines/styles
* Pull Request procedures
 * e.g. Do we Squash and Merge branches or Rebase and Merge? Do we include the Card Number in the PR Message or the Branch Name? Do we open up

 

## How about a Checklist to help out?


Here is a check-list of small, (mostly) easy to accomplish items that build off each other to lead to Deploy By Commit
 

> Note! While this list is in a logical order to proceed, it does not have to be 100% followed in this order!
>
> For Example: Your project only has a 30% test coverage, and the tests it does have are not very good. You can still add these tests and automation of them to your pipeline - Sure its not really a protection at this point, but something is better than nothing! Don’t let perfect be the enemy of done. Even if they don’t do a very good job, at least they are there in automation already - then as your test suites improve, it's already part of your pipeline!
> 
> Note! This is not everything. There are other steps to be done and other things that can/should happen before this point and after. But this gives a good goal oriented check-list to build from.


### Encourage Devs to
 
* Use Test Driven (or Behavior Driven) Development
* Participate in development of, and Own the Pipeline
* Participate in and own the Team Style Guidelines
* Understand and document as many of the steps as possible to deploy your product from nothing

### Protect Main

* Protect Main and allow only commits made through Pull Request.
* Add a Codeowners file to the the repo to limit who can approve Pull Requests and require at least one approver to sign of on it.
* Automatically lint all code before it is committed (Pre Commit, or automation that lints and commits to that PR)
* Automatically run as many as possible tests against that PR branch, and report the status (all of them if possible! But at the very least Unit Tests)

### Work to put your product entirely under Infrastructure as Code.

* Get most of your Cloud Resources into IaC
* Write Scripts (bash, powershell, python, or other) that can be run in a pipeline to do anything you feel has to be manual
* review how those scripts and your IaC interact, and try to consolidate into the IaC if possible
* Use the IaC commands (terraform plan, terraform apply ) at first to deploy changes to the cloud rather than making manual changes in the cloud portal

### Build a Pipeline to Automate Deployment


* Start with automation for at least such things like terraform plan and terraform apply
* Connect those steps together in a pipeline
* Connect that pipeline to your repo and trigger it by commits from main
* Add testing steps to that pipeline
* Add reporting to that pipeline
* Set up an Immutable Production Environment
 

### Ensure your Infrastructure as Code can deploy ad-hoc, ephemeral environments without disrupting your production environment

* Ensure your IaC or similar can destroy those ad-hoc, ephemeral environments
* Move your testing to be done against those ad-hoc, ephemeral environments
* Programmatically remove the ability to manipulate the prod environment manually


## Where to go next?

Deploy from Commit is just one step in the DevOps process. There are so many other things that can happen before and after. Some suggestions:


* **Include in your pipeline Canaries, Blue Green, and/or Rollover deployment strategies, ect.** Deploying through extensive test suites is excellent, but mistakes will still be made and bugs will still make it to prod. Building into your pipeline the ability to roll back to a “last good state” on detected failures after production is super useful to give your devs more time to diagnose the problem and fix it rather than trying to get the service back online.
* **Automate Lead-Time Tracking** by tying your Cards/Stories “Done” status to the pipeline - and like Deploy from Commit requires an immutable production environment, set the Done Status to only be able to be set by the Pipeline
* **Automate Documentation** through the pipeline, using Javadoc comments or the like to automate building of API docs.
* **Encourage and Set up Contract Tests** between services, to allow an individual service to deploy as often and as quickly as they like as long as the Contract that has been established between it and its dependent services is maintained as green
* **Increase the reliability of Tests by mocking services built form the contracts.** If your product knows the API Contract that its dependencies are expecting, you - and the dependant services - can reliably build mocks from those contracts, meaning tests no longer have to reach out to the service in question - and therefor fail less often.